{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cad694b-d36e-4b85-a0b6-e03f1ad7ec01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "940bc869-c835-4538-b43d-af7fcbda4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "D:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from openbiolink.obl2021 import OBL2021Dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch.utils.data\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea43a730-5068-47a6-9a4b-5f9095147a71",
   "metadata": {},
   "source": [
    "# Set Manual Seed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69840a2e-91ea-4b2e-b3a0-6159d76adf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2022)\n",
    "torch.cuda.manual_seed_all(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f9f09-aebf-474c-b1c7-93dff25e026d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accessing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd940b1b-da8d-4968-a340-d3a162b7ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found in D:\\programming repo-1\\university of glasgow\\msc project\\MSc.Project\\obl2021, omitting download...\n"
     ]
    }
   ],
   "source": [
    "obl_dataset = OBL2021Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5b5355-08ff-4e87-848f-49695a6d0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training, validation and test sets\n",
    "\n",
    "#obl_train_dataset = obl_dataset.training\n",
    "#obl_valid_dataset = obl_dataset.validation\n",
    "#obl_test_dataset = obl_dataset.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54eeb4ec-9039-4f85-99f1-fd561037c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training tensor is :  torch.Size([4192002, 3])\n",
      "The shape of the validation tensor is :  torch.Size([186301, 3])\n",
      "The shape of the testing tensor is :  torch.Size([180964, 3])\n",
      "The data type of the training tensor is :  torch.int64\n",
      "The data type of the validation tensor is :  torch.int64\n",
      "The data type of the testing tensor is :  torch.int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(1), tensor(0), tensor(42), tensor(2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking out the tensor shape\n",
    "print('The shape of the training tensor is : ', obl_dataset.training.shape)\n",
    "print('The shape of the validation tensor is : ', obl_dataset.validation.shape)\n",
    "print('The shape of the testing tensor is : ', obl_dataset.testing.shape)\n",
    "\n",
    "#checking out the tensor dtype\n",
    "print('The data type of the training tensor is : ', obl_dataset.training.dtype)\n",
    "print('The data type of the validation tensor is : ', obl_dataset.validation.dtype)\n",
    "print('The data type of the testing tensor is : ', obl_dataset.testing.dtype)\n",
    "\n",
    "torch.max(obl_dataset.training[:,0]), torch.max(obl_dataset.training[:,2]), torch.max(obl_dataset.validation[:,0]), torch.max(obl_dataset.validation[:,2])\n",
    "torch.min(obl_dataset.training[:,0]), torch.min(obl_dataset.training[:,2]), torch.min(obl_dataset.validation[:,0]), torch.min(obl_dataset.validation[:,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40f15b-19fa-48f0-9d5f-93190d611905",
   "metadata": {},
   "source": [
    "# Embedding Models:\n",
    "\n",
    "## TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecc24a83-2056-40b6-90e4-98ecda932329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(self, device, num_entity, num_relation, emb_dim, gamma):\n",
    "        super(TransE, self).__init__()\n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_entity = num_entity\n",
    "        self.num_relation = num_relation\n",
    "        \n",
    "        #initialize entity embeddings\n",
    "        self.entity_emb = self.initialize_emb(self.num_entity, self.emb_dim)\n",
    "\n",
    "        #initialie relation embeddings\n",
    "        self.relation_emb = self.initialize_emb(self.num_relation, self.emb_dim)\n",
    "        self.relation_emb.weight.data.div_(self.relation_emb.weight.data.norm(p=2, dim=1, keepdim=True))\n",
    "        #create the loss function\n",
    "        self.loss_fn = nn.MarginRankingLoss(margin=gamma)\n",
    "        \n",
    "\n",
    "    def initialize_emb(self, num_emb, emb_dim):\n",
    "        emb_weight_range = 6 / math.sqrt(emb_dim)\n",
    "        emb = nn.Embedding(num_embeddings=num_emb, embedding_dim=emb_dim, device=self.device)\n",
    "        emb.weight.data.uniform_( -emb_weight_range, emb_weight_range )\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, pos_triplet, neg_triplet):\n",
    "        self.entity_emb.weight.data.div_(self.entity_emb.weight.data.norm(p=2, dim=1, keepdim=True))\n",
    "        pos_distance = self.cal_distance(pos_triplet)\n",
    "        neg_distance = self.cal_distance(neg_triplet)\n",
    "        return self.loss_fn(pos_distance, neg_distance, torch.tensor([[-1]]*pos_triplet.shape[0], dtype=torch.int64, device=self.device))\n",
    "    \n",
    "    def cal_distance(self, triplet):\n",
    "        head = triplet[:,0]\n",
    "        relation = triplet[:,1]\n",
    "        tail = triplet[:,2]\n",
    "        #print(head.shape)\n",
    "        return (self.entity_emb(head) + self.relation_emb(relation) - self.entity_emb(tail))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76939c0b-2475-4fd3-9792-e5b54fd7947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test transe_model, remove later\n",
    "#transe_model = TransE(device = 'cuda', num_entity = 100, num_relation = 10, emb_dim = 100, gamma = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21841d53-0e13-4625-b71a-d3e00ce60c47",
   "metadata": {},
   "source": [
    "### Create Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34f8f044-b2a9-4262-81b3-e91a0f03f9fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncount = 0\\nfor i in dataset:\\n    print(i)\\n    count +=1\\n    if count == 10:\\n        break\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "class Create_dataset(torch.utils.data.IterableDataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.size = data.size()\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return iter(self.data)\n",
    "    \n",
    "    def size(self):\n",
    "        return self.size\n",
    "\n",
    "obl_train_dataset = TensorDataset(obl_dataset.training)\n",
    "obl_valid_dataset = TensorDataset(obl_dataset.validation)\n",
    "obl_test_dataset = TensorDataset(obl_dataset.testing)\n",
    "\n",
    "dataset = Create_dataset(obl_dataset.training)\n",
    "\n",
    "print(type(obl_dataset.training.shape[0]))\n",
    "print(obl_dataset.training.size())\n",
    "'''\n",
    "\n",
    "'''\n",
    "count = 0\n",
    "for i in dataset:\n",
    "    print(i)\n",
    "    count +=1\n",
    "    if count == 10:\n",
    "        break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7dc49-808b-40e7-b9d7-8d335d25a74b",
   "metadata": {},
   "source": [
    "### Create DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd42b2b6-c9a5-4fe2-af05-e58da2572646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size, shuffle):\n",
    "    tensor_dataset = TensorDataset(dataset)\n",
    "    return DataLoader(tensor_dataset, batch_size=batch_size, shuffle=shuffle) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcee9e66-7059-4f3e-af9f-5b3e8a109cdc",
   "metadata": {},
   "source": [
    "### Sample Corrupted Triplet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5bdcaac-a999-4045-bd03-ca3f859d5211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corr_triplet(num_entity, sample_data):\n",
    "    corr_triplet = sample_data.clone().detach()\n",
    "    head_or_tail = torch.randint( 0, 2, (1,))\n",
    "    if head_or_tail == 0:\n",
    "        corr_triplet[:,0] = torch.randint(0, num_entity, (sample_data.shape[0],))\n",
    "    else:\n",
    "        corr_triplet[:,2] = torch.randint(0, num_entity, (sample_data.shape[0],))\n",
    "    return corr_triplet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e85af-3bde-4bf8-ae58-c32450a0ba7b",
   "metadata": {},
   "source": [
    "### Training Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90e27852-349f-4bf9-ab9c-a86affeb3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transe(model, data_loader, optimizer, epoch, num_entity, device):\n",
    "    for i in range(epoch):\n",
    "        for index, batch_data in enumerate(data_loader):  \n",
    "            #print(len(batch_data))\n",
    "            #print(batch_data[0][0])\n",
    "            #break\n",
    "            sample_data = batch_data[0]\n",
    "            corr_sample_data = create_corr_triplet(num_entity=num_entity, sample_data=sample_data)\n",
    "            sample_data = sample_data.to(device)\n",
    "            corr_sample_data = corr_sample_data.to(device)\n",
    "            loss = model(sample_data, corr_sample_data)\n",
    "            loss = loss.mean()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(i, 'epoch is done')\n",
    "        print('Training loss is: ', loss)\n",
    "        evaluate_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7787801-6f53-47dc-a75b-19f9f65ba1ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluation Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec33ed26-2607-4155-b84c-308bbfb7f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52220e15-5812-4db8-b42e-be7f906e798b",
   "metadata": {},
   "source": [
    "### Set parameters and call train TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14c6eecd-061f-4fdd-abf7-2fa3ceb0f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch is done\n",
      "Training loss is:  tensor(0.0432, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "1 epoch is done\n",
      "Training loss is:  tensor(0.0411, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "2 epoch is done\n",
      "Training loss is:  tensor(0.0431, device='cuda:0', grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(transe_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m      4\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m create_dataloader(obl_dataset\u001b[38;5;241m.\u001b[39mtraining, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mtrain_transe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtranse_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_entity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m184732\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mtrain_transe\u001b[1;34m(model, data_loader, optimizer, epoch, num_entity, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m batch_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m corr_sample_data \u001b[38;5;241m=\u001b[39m create_corr_triplet(num_entity\u001b[38;5;241m=\u001b[39mnum_entity, sample_data\u001b[38;5;241m=\u001b[39msample_data)\n\u001b[1;32m----> 9\u001b[0m sample_data \u001b[38;5;241m=\u001b[39m \u001b[43msample_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m corr_sample_data \u001b[38;5;241m=\u001b[39m corr_sample_data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(sample_data, corr_sample_data)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "transe_model = TransE(device = 'cuda', num_entity = 184732, num_relation = 28, emb_dim = 50, gamma = 0.01)\n",
    "optimizer = torch.optim.SGD(transe_model.parameters(), lr=0.01)\n",
    "\n",
    "data_loader = create_dataloader(obl_dataset.training, batch_size=512, shuffle=True)\n",
    "train_transe(model=transe_model, data_loader=data_loader, optimizer=optimizer, epoch=20, num_entity=184732, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f820fee-ade0-41a8-b1e9-d00de90ceee5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f769e26-2623-4590-952d-66272ca1307a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
