{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cad694b-d36e-4b85-a0b6-e03f1ad7ec01",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "940bc869-c835-4538-b43d-af7fcbda4d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python38\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "D:\\python38\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from openbiolink.obl2021 import OBL2021Dataset\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44f9f09-aebf-474c-b1c7-93dff25e026d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Accessing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd940b1b-da8d-4968-a340-d3a162b7ed7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found in D:\\programming repo-1\\university of glasgow\\msc project\\MSc.Project\\obl2021, omitting download...\n"
     ]
    }
   ],
   "source": [
    "obl_dataset = OBL2021Dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b5b5355-08ff-4e87-848f-49695a6d0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training, validation and test sets\n",
    "\n",
    "#obl_train_dataset = obl_dataset.training\n",
    "#obl_valid_dataset = obl_dataset.validation\n",
    "#obl_test_dataset = obl_dataset.testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54eeb4ec-9039-4f85-99f1-fd561037c703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training tensor is :  torch.Size([4192002, 3])\n",
      "The the data type of the training tensor is :  torch.int64\n"
     ]
    }
   ],
   "source": [
    "#checking out the tensor shape\n",
    "print('The shape of the training tensor is : ', obl_dataset.training.shape)\n",
    "\n",
    "#checking out the tensor dtype\n",
    "print('The the data type of the training tensor is : ', obl_dataset.training.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40f15b-19fa-48f0-9d5f-93190d611905",
   "metadata": {},
   "source": [
    "# Embedding Models:\n",
    "\n",
    "## TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc24a83-2056-40b6-90e4-98ecda932329",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransE(nn.Module):\n",
    "    def __init__(self, device, num_entity, num_relation, emb_dim, gamma):\n",
    "        super(TransE, self).__init__()\n",
    "        self.device = device\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_entity = num_entity\n",
    "        self.num_relation = num_relation\n",
    "        \n",
    "        #initialize entity embeddings\n",
    "        self.entity_emb = self.initialize_emb(self.num_entity, self.emb_dim)\n",
    "\n",
    "        #initialie relation embeddings\n",
    "        self.relation_emb = self.initialize_emb(self.num_relation, self.emb_dim)\n",
    "        self.relation_emb.weight.data.div_(self.relation_emb.weight.data.norm(p=2, dim=1, keepdim=True))\n",
    "        #create the loss function\n",
    "        loss_fn = nn.MarginRankingLoss(margin=gamma)\n",
    "        \n",
    "\n",
    "    def initialize_emb(self, num_emb, emb_dim):\n",
    "        emb_weight_range = 6 / math.sqrt(emb_dim)\n",
    "        emb = nn.Embedding(num_embeddings=num_emb, embedding_dim=emb_dim)\n",
    "        emb.weight.data.uniform_( -emb_weight_range, emb_weight_range )\n",
    "        return emb\n",
    "    \n",
    "    def forward(self, pos_triplet, neg_triplet):\n",
    "        self.entity_emb.weight.data.div_(self.entity_emb.weight.data.norm(p=2, dim=1, keepdim=True))\n",
    "        pos_distance = cal_distance(pos_triplet)\n",
    "        neg_distance = cal_distance(neg_triplet)\n",
    "        return loss_fn(pos_distance, neg_distance, torch.tensor([-1], dtype=torch.int64, device=self.device))\n",
    "    \n",
    "    def cal_distance(self, triplet):\n",
    "        head = triplet[:,0]\n",
    "        relation = triplet[:,1]\n",
    "        tail = triplet[:,2]\n",
    "        return (self.entity_emb(head) + self.relation(relation) - self.entity_emb(tail))\n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76939c0b-2475-4fd3-9792-e5b54fd7947b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test transe_model, remove later\n",
    "transe_model = TransE(device = 'cuda', num_entity = 100, num_relation = 10, emb_dim = 100, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21841d53-0e13-4625-b71a-d3e00ce60c47",
   "metadata": {},
   "source": [
    "### Create Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f8f044-b2a9-4262-81b3-e91a0f03f9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "obl_train_dataset = TensorDataset(obl_dataset.training)\n",
    "obl_valid_dataset = TensorDataset(obl_dataset.validation)\n",
    "obl_test_dataset = TensorDataset(obl_dataset.testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb7dc49-808b-40e7-b9d7-8d335d25a74b",
   "metadata": {},
   "source": [
    "### Create DataLoader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd42b2b6-c9a5-4fe2-af05-e58da2572646",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(dataset, batch_size, shuffle):\n",
    "    tensor_dataset = TensorDataset(dataset)\n",
    "    return DataLoader(tensor_dataset, batch_size=batch_size, shuffle=shuffle) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e85af-3bde-4bf8-ae58-c32450a0ba7b",
   "metadata": {},
   "source": [
    "### Training Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90e27852-349f-4bf9-ab9c-a86affeb3606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_transe(data_loader, epoch, device):\n",
    "    for i in range(epoch):\n",
    "        for index, batch_data in enumerate(data_loader):  \n",
    "            print(len(batch_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7787801-6f53-47dc-a75b-19f9f65ba1ae",
   "metadata": {},
   "source": [
    "### Testing Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec33ed26-2607-4155-b84c-308bbfb7f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_transe():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52220e15-5812-4db8-b42e-be7f906e798b",
   "metadata": {},
   "source": [
    "### Set parameters and call train TransE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "14c6eecd-061f-4fdd-abf7-2fa3ceb0f5bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorDataset' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m transe_model \u001b[38;5;241m=\u001b[39m TransE(device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m, num_entity \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, num_relation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m, emb_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m, gamma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.1\u001b[39m)\n\u001b[0;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(transe_model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m data_loader \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobl_train_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m train_transe(data_loader\u001b[38;5;241m=\u001b[39mdata_loader, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mcreate_dataloader\u001b[1;34m(dataset, batch_size, shuffle)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_dataloader\u001b[39m(dataset, batch_size, shuffle):\n\u001b[1;32m----> 2\u001b[0m     tensor_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mTensorDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataLoader(tensor_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39mshuffle)\n",
      "File \u001b[1;32mD:\\python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:184\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, *tensors)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "File \u001b[1;32mD:\\python38\\lib\\site-packages\\torch\\utils\\data\\dataset.py:184\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mtensors: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mtensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m tensor\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize mismatch between tensors\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensors \u001b[38;5;241m=\u001b[39m tensors\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "transe_model = TransE(device = 'cuda', num_entity = 100, num_relation = 10, emb_dim = 100, gamma = 0.1)\n",
    "optimizer = torch.optim.Adam(transe_model.parameters(), lr=0.0001)\n",
    "\n",
    "data_loader = create_dataloader(obl_train_dataset, batch_size=128, shuffle=True)\n",
    "train_transe(data_loader=data_loader, epoch=20, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1105861-f8bb-4556-a090-ba002e445cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90e4722-e088-4c90-8890-2b5e9b6360f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
